{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d75da45",
   "metadata": {},
   "source": [
    "##### MAIN OVERVIEW:\n",
    "##### Written 2023/08 by Christina Lebonville\n",
    "##### Last updated: 2023/08/10\n",
    "###### For batch processing each model's inference on all videos. \n",
    "\n",
    "###### Can run in this notebook but will not be able to see the progress bar. To be able to monitor the progress of the inference, you will need to go into Anaconda and activate the DEG environment like you were going to open the GUI, but instead of typing \"deepethogram\" to open the GUI, type \"python\" to allow the command line to accept the Python code below. \n",
    "\n",
    "###### REQUIRED KERNEL: \"deg\"\n",
    "\n",
    "- Opens DEG Project & required modules\n",
    "- Creates, checks, and ammends config file used for inference\n",
    "- Runs inference on all videos\n",
    "- Checks random file to make sure inference was successful\n",
    "- MUST use \"python -m ipykernel install --user --name=deg\" in anaconda command line to make the deg environment detectable in the notebook and then select the environment in the notebook before running the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6574bfe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3 UNLABELED ROWS!VIDEO WILL NOT BE USED FOR FEATURE_EXTRACTOR OR SEQUENCE TRAINING.\n",
      "3 UNLABELED ROWS!VIDEO WILL NOT BE USED FOR FEATURE_EXTRACTOR OR SEQUENCE TRAINING.\n",
      "3 UNLABELED ROWS!VIDEO WILL NOT BE USED FOR FEATURE_EXTRACTOR OR SEQUENCE TRAINING.\n",
      "3 UNLABELED ROWS!VIDEO WILL NOT BE USED FOR FEATURE_EXTRACTOR OR SEQUENCE TRAINING.\n",
      "3 UNLABELED ROWS!VIDEO WILL NOT BE USED FOR FEATURE_EXTRACTOR OR SEQUENCE TRAINING.\n",
      "3 UNLABELED ROWS!VIDEO WILL NOT BE USED FOR FEATURE_EXTRACTOR OR SEQUENCE TRAINING.\n",
      "3 UNLABELED ROWS!VIDEO WILL NOT BE USED FOR FEATURE_EXTRACTOR OR SEQUENCE TRAINING.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Loaded Successfully Unless Substantial Errors Reported Above\n"
     ]
    }
   ],
   "source": [
    "import deepethogram\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "from deepethogram import configuration, postprocessing, projects, utils, file_io\n",
    "from deepethogram.debug import print_dataset_info\n",
    "from deepethogram.feature_extractor.inference import feature_extractor_inference\n",
    "from deepethogram.sequence.inference import sequence_inference\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "config_file='project_config.yaml'\n",
    "data_path='H://TrueBout-Gen4_deepethogram/DATA'\n",
    "project_path='H://TrueBout-Gen4_deepethogram/'\n",
    "\n",
    "\n",
    "files = os.listdir(project_path)\n",
    "assert 'DATA' in files, 'DATA directory not found! {}'.format(files)\n",
    "assert 'models' in files, 'models directory not found! {}'.format(files)\n",
    "assert 'project_config.yaml' in files, 'project config not found! {}'.format(files)\n",
    "\n",
    "print_dataset_info(os.path.join(project_path, 'DATA'))\n",
    "print('Project Loaded Successfully Unless Substantial Errors Reported Above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fab0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split:\n",
      "  reload: true\n",
      "  file: null\n",
      "  train_val_test:\n",
      "  - 0.8\n",
      "  - 0.2\n",
      "  - 0.0\n",
      "compute:\n",
      "  fp16: false\n",
      "  num_workers: 8\n",
      "  batch_size: 32\n",
      "  min_batch_size: 8\n",
      "  max_batch_size: 512\n",
      "  distributed: false\n",
      "  gpu_id: 0\n",
      "  dali: false\n",
      "  metrics_workers: 0\n",
      "reload:\n",
      "  overwrite_cfg: false\n",
      "  latest: false\n",
      "notes: null\n",
      "log:\n",
      "  level: info\n",
      "augs:\n",
      "  brightness: 0.25\n",
      "  contrast: 0.1\n",
      "  hue: 0.1\n",
      "  saturation: 0.1\n",
      "  color_p: 0.5\n",
      "  grayscale: 0.5\n",
      "  crop_size: null\n",
      "  resize:\n",
      "  - 224\n",
      "  - 224\n",
      "  dali: false\n",
      "  random_resize: false\n",
      "  pad: null\n",
      "  LR: 0.5\n",
      "  UD: 0.0\n",
      "  degrees: 10\n",
      "  normalization:\n",
      "    'N': 29626368000\n",
      "    mean:\n",
      "    - 0.44525026569574694\n",
      "    - 0.07219969618068768\n",
      "    - 0.025669157630121873\n",
      "    std:\n",
      "    - 0.13295815236680175\n",
      "    - 0.04349840018167546\n",
      "    - 0.029149261942258725\n",
      "feature_extractor:\n",
      "  arch: resnet50\n",
      "  fusion: average\n",
      "  sampler: null\n",
      "  final_bn: false\n",
      "  sampling_ratio: null\n",
      "  final_activation: sigmoid\n",
      "  dropout_p: 0.25\n",
      "  n_flows: 10\n",
      "  n_rgb: 1\n",
      "  curriculum: false\n",
      "  inputs: both\n",
      "  weights: latest\n",
      "  n_flow: 10\n",
      "train:\n",
      "  steps_per_epoch:\n",
      "    train: 1000\n",
      "    val: 200\n",
      "    test: 20\n",
      "  num_epochs: 50\n",
      "  loss_weight_exp: 0.8\n",
      "flow_generator:\n",
      "  type: flow_generator\n",
      "  flow_loss: MotionNet\n",
      "  flow_max: 10\n",
      "  input_images: 11\n",
      "  flow_sparsity: false\n",
      "  smooth_weight_multiplier: 1.0\n",
      "  sparsity_weight: 0.0\n",
      "  loss: MotionNet\n",
      "  max: 5\n",
      "  n_rgb: 11\n",
      "  arch: MotionNet\n",
      "  weights: latest\n",
      "  'n': 10\n",
      "inference:\n",
      "  directory_list: all\n",
      "  ignore_error: false\n",
      "  overwrite: false\n",
      "  use_loaded_model_cfg: true\n",
      "postprocessor:\n",
      "  type: min_bout_per_behavior\n",
      "  min_bout_length: 1\n",
      "cmap: deepethogram\n",
      "control_arrow_jump: 31\n",
      "label_view_width: 31\n",
      "prediction_opacity: 0.2\n",
      "preset: deg_m\n",
      "project:\n",
      "  class_names:\n",
      "  - background\n",
      "  - C\n",
      "  - NC\n",
      "  config_file: project_config.yaml\n",
      "  data_path: H:\\TrueBout-Gen4_deepethogram\\DATA\n",
      "  labeler: null\n",
      "  model_path: H:\\TrueBout-Gen4_deepethogram\\models\n",
      "  name: TrueBout\n",
      "  path: H:\\TrueBout-Gen4_deepethogram\n",
      "  pretrained_path: H:\\TrueBout-Gen4_deepethogram\\models\\pretrained_models\n",
      "run:\n",
      "  type: inference\n",
      "  model: feature_extractor\n",
      "sequence:\n",
      "  filter_length: 15\n",
      "unlabeled_alpha: 0.1\n",
      "vertical_arrow_jump: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### Check the feature extractor configuration to make sure everything is correct\n",
    "#### This is where you can manually sets some of the configuration fields\n",
    "cfg = configuration.make_feature_extractor_inference_cfg(project_path=project_path)\n",
    "\n",
    "cfg.feature_extractor.weights = 'latest'\n",
    "cfg.flow_generator.weights = 'latest'\n",
    "# make sure errors are thrown\n",
    "cfg.inference.ignore_error = False\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a772e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Check your data path for updated prediction files.\n"
     ]
    }
   ],
   "source": [
    "##Run Feature Extractor model inference!\n",
    "feature_extractor_inference(cfg)\n",
    "print('Success! Feature extractor model used to infer predictions on all videos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31862cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Double-check a random record to make sure an entry for the feature extractor model exists\n",
    "##in this case either ResNet18 (deg_f), ResNet50 (deg_m), or 3D-ResNet34 (deg_s)\n",
    "# this just parses our DATA directory, to get the path to each file for each video\n",
    "records = projects.get_records_from_datadir(os.path.join(project_path, 'DATA'))\n",
    "animal = random.choice(list(records.keys()))\n",
    "record = records[animal]\n",
    "\n",
    "# I call the file output by inference the `outputfile` in various places in the code\n",
    "outputfile = record['output']\n",
    "\n",
    "utils.print_hdf5(outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Check the sequence extractor configuration to make sure everything is correct\n",
    "#### This is where you can manually sets some of the configuration fields\n",
    "\n",
    "cfg = configuration.make_sequence_inference_cfg(project_path)\n",
    "cfg.sequence.weights = 'latest'\n",
    "cfg.inference.ignore_error = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b638e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run Sequence model inference!\n",
    "sequence_inference(cfg)\n",
    "print('Success! Sequence model used to infer predictions on all videos. Ready to proceed to batch prediction export.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Double-check a random record to make sure an entry for the model exists - in this case tgmj\n",
    "\n",
    "# this just parses our DATA directory, to get the path to each file for each video\n",
    "records = projects.get_records_from_datadir(os.path.join(project_path, 'DATA'))\n",
    "animal = random.choice(list(records.keys()))\n",
    "record = records[animal]\n",
    "\n",
    "# I call the file output by inference the `outputfile` in various places in the code\n",
    "outputfile = record['output']\n",
    "\n",
    "utils.print_hdf5(outputfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deg",
   "language": "python",
   "name": "deg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
